{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"43b49bed-f357-461a-bdc8-8a257bce2916\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(global) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (window._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    window._bokeh_onload_callbacks = [];\n",
       "    window._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "\n",
       "  \n",
       "  if (typeof (window._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    window._bokeh_timeout = Date.now() + 5000;\n",
       "    window._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    if (window.Bokeh !== undefined) {\n",
       "      var el = document.getElementById(\"43b49bed-f357-461a-bdc8-8a257bce2916\");\n",
       "      el.textContent = \"BokehJS \" + Bokeh.version + \" successfully loaded.\";\n",
       "    } else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    delete window._bokeh_onload_callbacks\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    window._bokeh_onload_callbacks.push(callback);\n",
       "    if (window._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    window._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        window._bokeh_is_loading--;\n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"43b49bed-f357-461a-bdc8-8a257bce2916\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid '43b49bed-f357-461a-bdc8-8a257bce2916' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.5.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.5.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "      document.getElementById(\"43b49bed-f357-461a-bdc8-8a257bce2916\").textContent = \"BokehJS is loading...\";\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.5.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.5.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.5.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.5.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((window.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i](window.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < window._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!window._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      window._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"43b49bed-f357-461a-bdc8-8a257bce2916\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (window._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(this));"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Loading 2 **** \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Data/2017-4-14-18-36/exp_data-2017-4-14-18-36.dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-64b0cf74cc4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m### loadSessionDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# We can just tell members of the audience that any way they can get the data into a dataframe is OK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0msessionDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadSessionDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalysisParameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstartFresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstartFresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloadProcessed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloadProcessed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/evan/Dev/Lab/gazeinworld_demo/Modules/performFun.py\u001b[0m in \u001b[0;36mloadSessionDict\u001b[0;34m(analysisParameters, startFresh, loadProcessed)\u001b[0m\n\u001b[1;32m   1346\u001b[0m     \u001b[0;31m# if startFresh is False, try to load the pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mstartFresh\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m         \u001b[0msessionDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreateSecondaryDataframes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilePath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexpCfgName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msysCfgName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/evan/Dev/Lab/gazeinworld_demo/Modules/performFun.py\u001b[0m in \u001b[0;36mcreateSecondaryDataframes\u001b[0;34m(filePath, fileName, expCfgName, sysCfgName)\u001b[0m\n\u001b[1;32m   1366\u001b[0m     \u001b[0mReads\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msys\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     '''\n\u001b[0;32m-> 1368\u001b[0;31m     \u001b[0msessionDf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadPerformDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilePath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfileName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".dict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0msessionDf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalibDf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseperateCalib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msessionDf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/evan/Dev/Lab/gazeinworld_demo/Modules/PerformParser.py\u001b[0m in \u001b[0;36mreadPerformDict\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# read\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdictFileToDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mgroupnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/evan/Dev/Lab/gazeinworld_demo/Modules/PerformParser.py\u001b[0m in \u001b[0;36mdictFileToDataFrame\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mnan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NaN'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# NOQA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# TODO: remove temp change when new data is recorded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Data/2017-4-14-18-36/exp_data-2017-4-14-18-36.dict'"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../Modules/\")\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "print(os.getcwd())\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from scipy import signal as sig\n",
    "\n",
    "import performFun as pF\n",
    "import catchE1Funs as expFun\n",
    "import recalibration as rc\n",
    "\n",
    "from plottingFuns import *\n",
    "from analysisParameters import loadParameters\n",
    "\n",
    "bkP.output_notebook()\n",
    "\n",
    "fileTime = '2017-4-14-18-36'\n",
    "\n",
    "analysisParameters = loadParameters(fileTime)\n",
    "startFresh = True\n",
    "loadProcessed = False\n",
    "\n",
    "##############################################################################\n",
    "##############################################################################\n",
    "### loadSessionDict\n",
    "# We can just tell members of the audience that any way they can get the data into a dataframe is OK\n",
    "sessionDict = pF.loadSessionDict(analysisParameters, startFresh=startFresh, loadProcessed=loadProcessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calc cyc gaze direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create cyclopean gaze vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm pretending we dont' have cycEyeInHead.  Why?  I don't think the eye tracker gives it to you for free.  Lets begin by dropping it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sessionDict['raw'] = sessionDict['raw'].drop('cycEyeInHead', axis=1, level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take the average of the two vectors, then normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Wow.  This method is actually quite slow compared to the numpy method.  I'm surprised!\n",
    "cycEyeInHeadDf = sessionDict['raw'].apply(lambda x: (x['rightEyeInHead'] + x['leftEyeInHead']) / 2.0, axis=1)\n",
    "cycEyeInHeadDf[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cycEyeInHeadDf = np.add(sessionDict['raw']['rightEyeInHead'], sessionDict['raw']['leftEyeInHead']) / 2\n",
    "cycEyeInHeadDf.columns = pd.MultiIndex.from_tuples([('cycEyeInHead','X'),('cycEyeInHead','Y'),('cycEyeInHead','Z')])\n",
    "cycEyeInHeadDf[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalizeDirection(xyz):\n",
    "    return xyz/np.linalg.norm(xyz)\n",
    "\n",
    "cycEyeInHeadDf = cycEyeInHeadDf.apply(lambda xyz: normalizeDirection(xyz), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add new dataframe to sessionDict['processed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sessionDict['processed'] = pd.concat([sessionDict['processed'], cycEyeInHeadDf], axis=1, verify_integrity=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that we have the cyclopean eye-in-head vector, we can apply our head transformation matrix to position it in the real world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note that this requires that we know what direction is 'forward' in the SMI glasses space, and in our own head's local coordinate system, wehre straight ahead is 0,0,1.  Up is 0,1,0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this operation requires information spread across two dataframes.\n",
    "So, as a first step, we must create a temporary dataframe with the columns of data that we will need of our operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newDf = pd.concat([sessionDict['processed']['cycEyeInHead'], sessionDict['raw']['viewMat']],\n",
    "          axis=1, keys=['cycEyeInHead','viewMatrix'])\n",
    "\n",
    "newDf[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, lets apply a function to each row that multiplies the data by the transform.  This should be a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# THis is the. only working implementation I've found. Ungh.\n",
    "for fr in range(0,10): #range(len(sessionDict['raw']['viewMat'])):\n",
    "    mat = sessionDict['raw']['viewMat'].values[fr].reshape([4,4]).T\n",
    "    xyzw = np.append(sessionDict['processed']['cycEyeInHead'].values[fr], True) # The True converst into a 1:  [x y z 1]\n",
    "    print np.dot(mat,xyzw)[0:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_fr_XYZ = [np.dot(sessionDict['raw']['viewMat'].values[fr].reshape([4,4]).T,\n",
    "                     np.append(sessionDict['processed']['cycEyeInHead'].values[fr],1)) for fr in range(0,10)]\n",
    "\n",
    "out_fr_XYZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I really want to solve this in a way that will allow use of the apply command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are some failed attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Attempt one\n",
    "#newDf.apply(lambda row: np.dot(row['viewMatrix'].values.reshape([4,4]).T,[0,0,1.0,0]),axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Attempt two\n",
    "#def multByMatrix(matrix_fr,xyz_fr,translate = True):       \n",
    "#     out_fr_XYZ = np.array([ np.dot(matrix_fr.values[fr].reshape([4,4]).T,\n",
    "#                                    np.append(xyz_fr.values[fr],translate)) \n",
    "#                            for fr in range(len(xyz_fr))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eureeka!  It turns out that the output from the function must be a tuple, or you get the error....\n",
    "ValueError: Shape of passed values is (40415, 3), indices imply (40415, 19)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fuck it!  We'll do it in a for loop.\n",
    "def multByMatrix(matrix, xyz, translate=True):\n",
    "        \n",
    "    mat = matrix.values.reshape([4,4]).T\n",
    "    xyzw = np.append(xyz,True)\n",
    "    xyzOut = np.dot(mat, xyzw)\n",
    "    \n",
    "    # It seems to be an issue of the return type\n",
    "    #return xyzOut[0:3] # THis does not work\n",
    "    #return [1,2,3] # THis does\n",
    "\n",
    "    #Eureeka!  You must return a tuple. This is pretty fast.\n",
    "    return (xyzOut[0], xyzOut[1], xyzOut[2])\n",
    "\n",
    "\n",
    "\n",
    "tranformedXYZ = newDf.apply(lambda row: multByMatrix(row['viewMatrix'],row['cycEyeInHead']),axis=1)\n",
    "tranformedXYZ[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do this for a few more things.  Plot. Success!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
